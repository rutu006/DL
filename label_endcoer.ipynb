{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "D9mOUatjCa3H"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "gYY5hUF2ELhw"
   },
   "outputs": [],
   "source": [
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/letter-recognition/letter-recognition.data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "d_MShIGYFAF0"
   },
   "outputs": [],
   "source": [
    "names = ['letter', 'x-box', 'y-box', 'width', 'height', 'onpix', 'x-bar', 'y-bar', 'x2bar', 'y2bar', 'xybar', 'x2ybr', 'xy2br', 'x-ege', 'xegvy', 'y-ege', 'yegvx']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "9-RUvrWSF0o9"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(url,names=names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "SUHCEDBiGIpy",
    "outputId": "82cafcdc-f8ff-49a5-844c-712313cf295b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>letter</th>\n",
       "      <th>x-box</th>\n",
       "      <th>y-box</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>onpix</th>\n",
       "      <th>x-bar</th>\n",
       "      <th>y-bar</th>\n",
       "      <th>x2bar</th>\n",
       "      <th>y2bar</th>\n",
       "      <th>xybar</th>\n",
       "      <th>x2ybr</th>\n",
       "      <th>xy2br</th>\n",
       "      <th>x-ege</th>\n",
       "      <th>xegvy</th>\n",
       "      <th>y-ege</th>\n",
       "      <th>yegvx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>D</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>N</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>G</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19995</th>\n",
       "      <td>D</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19996</th>\n",
       "      <td>C</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19997</th>\n",
       "      <td>T</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19998</th>\n",
       "      <td>S</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19999</th>\n",
       "      <td>A</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20000 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      letter  x-box  y-box  width  height  onpix  x-bar  y-bar  x2bar  y2bar  \\\n",
       "0          T      2      8      3       5      1      8     13      0      6   \n",
       "1          I      5     12      3       7      2     10      5      5      4   \n",
       "2          D      4     11      6       8      6     10      6      2      6   \n",
       "3          N      7     11      6       6      3      5      9      4      6   \n",
       "4          G      2      1      3       1      1      8      6      6      6   \n",
       "...      ...    ...    ...    ...     ...    ...    ...    ...    ...    ...   \n",
       "19995      D      2      2      3       3      2      7      7      7      6   \n",
       "19996      C      7     10      8       8      4      4      8      6      9   \n",
       "19997      T      6      9      6       7      5      6     11      3      7   \n",
       "19998      S      2      3      4       2      1      8      7      2      6   \n",
       "19999      A      4      9      6       6      2      9      5      3      1   \n",
       "\n",
       "       xybar  x2ybr  xy2br  x-ege  xegvy  y-ege  yegvx  \n",
       "0          6     10      8      0      8      0      8  \n",
       "1         13      3      9      2      8      4     10  \n",
       "2         10      3      7      3      7      3      9  \n",
       "3          4      4     10      6     10      2      8  \n",
       "4          6      5      9      1      7      5     10  \n",
       "...      ...    ...    ...    ...    ...    ...    ...  \n",
       "19995      6      6      4      2      8      3      7  \n",
       "19996     12      9     13      2      9      3      7  \n",
       "19997     11      9      5      2     12      2      4  \n",
       "19998     10      6      8      1      9      5      8  \n",
       "19999      8      1      8      2      7      2      8  \n",
       "\n",
       "[20000 rows x 17 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "aGQi8LXIGsfD"
   },
   "outputs": [],
   "source": [
    "#seaparte features and target\n",
    "X = data.drop('letter',axis=1)\n",
    "y= data['letter']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "Z89BroCTGx74"
   },
   "outputs": [],
   "source": [
    "#Encode target labels\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "-HHFEOLuG1lT"
   },
   "outputs": [],
   "source": [
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y_encoded,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "ACerX596G3rb"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "zpsMzPqUG5ZZ"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ruturaj\\anaconda3\\anaconda\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:86: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "#DEfine model\n",
    "model = Sequential([\n",
    "    # First hidden layer with 64 neurons and ReLU activation function\n",
    "    Dense(64,activation='relu',input_shape=(X_train.shape[1],)),\n",
    "    # Second hidden layer with 64 neurons and ReLU activation function\n",
    "    Dense(64,activation='relu'),\n",
    "    # Output layer with neurons equal to the number of classes (26 for letters\n",
    "    # A-Z) and softmax activation function\n",
    "    Dense(len(label_encoder.classes_), activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "MUJej8WIG7aI"
   },
   "outputs": [],
   "source": [
    "#Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hCaKFBW0G9I-",
    "outputId": "a9079418-d93f-4e64-de38-27a2813ad5aa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.3251 - loss: 2.5879 - val_accuracy: 0.6656 - val_loss: 1.1851\n",
      "Epoch 2/20\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.6941 - loss: 1.0722 - val_accuracy: 0.7494 - val_loss: 0.9443\n",
      "Epoch 3/20\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7468 - loss: 0.8807 - val_accuracy: 0.7719 - val_loss: 0.8222\n",
      "Epoch 4/20\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7822 - loss: 0.7582 - val_accuracy: 0.8019 - val_loss: 0.6972\n",
      "Epoch 5/20\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8036 - loss: 0.6709 - val_accuracy: 0.8206 - val_loss: 0.6525\n",
      "Epoch 6/20\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8177 - loss: 0.6089 - val_accuracy: 0.8369 - val_loss: 0.5652\n",
      "Epoch 7/20\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8407 - loss: 0.5470 - val_accuracy: 0.8344 - val_loss: 0.5522\n",
      "Epoch 8/20\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8485 - loss: 0.4933 - val_accuracy: 0.8575 - val_loss: 0.4755\n",
      "Epoch 9/20\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8568 - loss: 0.4685 - val_accuracy: 0.8525 - val_loss: 0.4826\n",
      "Epoch 10/20\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8671 - loss: 0.4295 - val_accuracy: 0.8712 - val_loss: 0.4309\n",
      "Epoch 11/20\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8763 - loss: 0.4042 - val_accuracy: 0.8800 - val_loss: 0.4086\n",
      "Epoch 12/20\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8800 - loss: 0.3890 - val_accuracy: 0.8881 - val_loss: 0.3896\n",
      "Epoch 13/20\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 957us/step - accuracy: 0.8872 - loss: 0.3693 - val_accuracy: 0.8894 - val_loss: 0.3593\n",
      "Epoch 14/20\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8979 - loss: 0.3380 - val_accuracy: 0.8881 - val_loss: 0.3720\n",
      "Epoch 15/20\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8983 - loss: 0.3242 - val_accuracy: 0.8919 - val_loss: 0.3356\n",
      "Epoch 16/20\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 956us/step - accuracy: 0.9021 - loss: 0.3069 - val_accuracy: 0.8950 - val_loss: 0.3420\n",
      "Epoch 17/20\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 978us/step - accuracy: 0.8997 - loss: 0.3152 - val_accuracy: 0.9025 - val_loss: 0.3113\n",
      "Epoch 18/20\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9078 - loss: 0.2968 - val_accuracy: 0.9056 - val_loss: 0.3038\n",
      "Epoch 19/20\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 982us/step - accuracy: 0.9193 - loss: 0.2573 - val_accuracy: 0.9056 - val_loss: 0.3001\n",
      "Epoch 20/20\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 954us/step - accuracy: 0.9171 - loss: 0.2567 - val_accuracy: 0.9050 - val_loss: 0.3098\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x28891f8dc90>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Train the model\n",
    "model.fit(X_train,y_train, epochs=20, batch_size=32, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eBjuqfYEBqY6",
    "outputId": "25189474-ebfb-4352-f858-52793482522a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "#save the trained model\n",
    "model.save(\"letter_recognition_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YoDF_FHsB3Ld",
    "outputId": "53a3f3ce-5fb4-4aa8-9450-703cb4a8d0bd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 893us/step - accuracy: 0.9045 - loss: 0.2859\n",
      "Test Accuracy:  0.9007499814033508\n"
     ]
    }
   ],
   "source": [
    "#Evaluate the model\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "print('Test Accuracy: ',test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "kMqjG32AHAbF"
   },
   "outputs": [],
   "source": [
    " #save the label encoder\n",
    "np.save(\"label_encoder_classes.npy\",label_encoder.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "zZOrmHPdF0cY"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "\n",
    "# Function to preprocess input dimensions\n",
    "def preprocess_input(dimensions):\n",
    "  # Convert dimensions to a numpy array and reshape it to match the input shape\n",
    "  # of the model\n",
    "  input_data=np.array(dimensions).reshape(1,-1)\n",
    "  return input_data\n",
    "\n",
    "\n",
    "# Function to predict the output using the trained model\n",
    "def predict_output(model,input_data,label_encoder):\n",
    "   # Use the model to predict the output\n",
    "  predicted_class=np.argmax(model.predict(input_data),axis=-1)\n",
    "  # Convert the predicted class index back to the original letter\n",
    "  predicted_letter = label_encoder.inverse_transform(predicted_class)\n",
    "  return predicted_letter[0]\n",
    "\n",
    "\n",
    "# Load the trained model and label encoder\n",
    "model=load_model(\"letter_recognition_model.h5\")\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.classes_ = np.load(\"label_encoder_classes.npy\",allow_pickle=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SyQCDj4zGOCD",
    "outputId": "f37b87be-cb0b-415d-e91b-765aeddafbb7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the dimensions separated by commas: 2,8,3,5,1,8,13,0,6,6,10,8,0,8,0,8\n"
     ]
    }
   ],
   "source": [
    " # Input dimensions dynamically from the user\n",
    "dimension_str = input(\"Enter the dimensions separated by commas: \")\n",
    "# Convert the input string to a list of integers\n",
    "dimensions = list(map(int, dimension_str.split(',')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1hNtAbwtI5Y3",
    "outputId": "1b04ca47-3a4a-4bc7-fc40-d69612086b68"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
      "Predicted Letter:  T\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Preprocess the input dimensions\n",
    "input_data = preprocess_input(dimensions)\n",
    "\n",
    "\n",
    "#2,8,3,5,1,8,13,0,6,6,10,8,0,8,0,8\n",
    "\n",
    "\n",
    "# Predict the output\n",
    "predicted_letter = predict_output(model, input_data,label_encoder)\n",
    "print(\"Predicted Letter: \",predicted_letter)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SekM-_6ACAhD"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
